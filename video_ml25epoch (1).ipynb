{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed947e1-d22f-4737-b3d9-8238c7a23b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking and installing dependencies ===\n",
      "\n",
      "=== Using device: cpu ===\n",
      "\n",
      "=== Creating training dataset (with augmentation) ===\n",
      "\n",
      "=== Loading dataset ===\n",
      "Loaded 50 real videos\n",
      "Loaded 10 NeuralTextures videos\n",
      "Loaded 10 FaceSwap videos\n",
      "Loaded 10 Deepfakes videos\n",
      "Loaded 10 Face2Face videos\n",
      "Loaded 10 FaceShifter videos\n",
      "Total fake videos: 50\n",
      "Total dataset size: 100 videos\n",
      "\n",
      "=== Creating validation/test dataset (no augmentation) ===\n",
      "\n",
      "=== Loading dataset ===\n",
      "Loaded 50 real videos\n",
      "Loaded 10 NeuralTextures videos\n",
      "Loaded 10 FaceSwap videos\n",
      "Loaded 10 Deepfakes videos\n",
      "Loaded 10 Face2Face videos\n",
      "Loaded 10 FaceShifter videos\n",
      "Total fake videos: 50\n",
      "Total dataset size: 100 videos\n",
      "\n",
      "Dataset split: Train=70, Val=15, Test=15\n",
      "\n",
      "======================================================================\n",
      "TRAINING IMPROVED CNN MODEL\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "Training CNN\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [24:25<00:00, 162.85s/it, loss=0.7051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.7140, Train Acc: 0.4714 | Val Loss: 0.7197, Val Acc: 0.4000\n",
      "âœ“ Saved best model with Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [25:17<00:00, 168.57s/it, loss=0.7744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.6970, Train Acc: 0.6286 | Val Loss: 0.7382, Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:44<00:00, 84.92s/it, loss=0.7356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.6406, Train Acc: 0.6857 | Val Loss: 0.7448, Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:46<00:00, 78.49s/it, loss=0.6762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.6331, Train Acc: 0.6000 | Val Loss: 0.7393, Val Acc: 0.4667\n",
      "âœ“ Saved best model with Val Acc: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:33<00:00, 77.08s/it, loss=0.4952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.5787, Train Acc: 0.7286 | Val Loss: 0.7016, Val Acc: 0.5333\n",
      "âœ“ Saved best model with Val Acc: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:03<00:00, 80.38s/it, loss=0.5719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.6023, Train Acc: 0.6429 | Val Loss: 0.6226, Val Acc: 0.6000\n",
      "âœ“ Saved best model with Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:06<00:00, 80.78s/it, loss=0.8821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.6180, Train Acc: 0.7000 | Val Loss: 0.5893, Val Acc: 0.6667\n",
      "âœ“ Saved best model with Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:05<00:00, 80.61s/it, loss=0.5545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.5596, Train Acc: 0.7571 | Val Loss: 0.5496, Val Acc: 0.8000\n",
      "âœ“ Saved best model with Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [13:01<00:00, 86.88s/it, loss=0.5212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.5269, Train Acc: 0.7714 | Val Loss: 0.5675, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:43<00:00, 78.11s/it, loss=0.6451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.4737, Train Acc: 0.8000 | Val Loss: 0.5224, Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:40<00:00, 77.79s/it, loss=0.6031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.5291, Train Acc: 0.7429 | Val Loss: 0.5492, Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:44<00:00, 78.29s/it, loss=0.7860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Learning rate reduced from 0.000100 to 0.000050\n",
      "Epoch 12: Train Loss: 0.5604, Train Acc: 0.7571 | Val Loss: 0.5601, Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:55<00:00, 79.45s/it, loss=0.3477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.4581, Train Acc: 0.7857 | Val Loss: 0.5435, Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:05<00:00, 80.60s/it, loss=0.3820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.4272, Train Acc: 0.8000 | Val Loss: 0.5813, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [13:16<00:00, 88.50s/it, loss=0.2997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.4746, Train Acc: 0.8000 | Val Loss: 0.4704, Val Acc: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:39<00:00, 84.35s/it, loss=0.7692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Learning rate reduced from 0.000050 to 0.000025\n",
      "Epoch 16: Train Loss: 0.4882, Train Acc: 0.8143 | Val Loss: 0.5271, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [13:26<00:00, 89.60s/it, loss=0.5222] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.4089, Train Acc: 0.8286 | Val Loss: 0.4965, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [22:37<00:00, 150.86s/it, loss=0.3393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.4215, Train Acc: 0.8714 | Val Loss: 0.5078, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [24:08<00:00, 160.95s/it, loss=0.6392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.4434, Train Acc: 0.8000 | Val Loss: 0.4191, Val Acc: 0.8667\n",
      "âœ“ Saved best model with Val Acc: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [23:55<00:00, 159.50s/it, loss=0.3344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.4588, Train Acc: 0.8143 | Val Loss: 0.3933, Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [23:54<00:00, 159.40s/it, loss=0.3521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss: 0.4192, Train Acc: 0.8286 | Val Loss: 0.3982, Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [24:01<00:00, 160.16s/it, loss=0.6463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss: 0.4984, Train Acc: 0.7571 | Val Loss: 0.4115, Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [24:01<00:00, 160.14s/it, loss=0.4556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Learning rate reduced from 0.000025 to 0.000013\n",
      "Epoch 23: Train Loss: 0.3749, Train Acc: 0.8429 | Val Loss: 0.3972, Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [19:41<00:00, 131.22s/it, loss=0.3170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss: 0.3733, Train Acc: 0.8571 | Val Loss: 0.4101, Val Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:21<00:00, 82.39s/it, loss=0.2921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss: 0.3813, Train Acc: 0.8714 | Val Loss: 0.4143, Val Acc: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating CNN: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:45<00:00, 22.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN Results:\n",
      "Accuracy: 0.8667\n",
      "Precision: 0.8182\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9000\n",
      "Confusion Matrix:\n",
      "[[4 2]\n",
      " [0 9]]\n",
      "\n",
      "======================================================================\n",
      "TRAINING IMPROVED TCN MODEL\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "Training TCN\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:46<00:00, 78.49s/it, loss=0.6622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.9906, Train Acc: 0.5429 | Val Loss: 0.6899, Val Acc: 0.6000\n",
      "âœ“ Saved best model with Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:35<00:00, 77.26s/it, loss=0.6762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.0516, Train Acc: 0.3857 | Val Loss: 0.7099, Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:21<00:00, 75.73s/it, loss=0.9614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.7319, Train Acc: 0.5857 | Val Loss: 0.7747, Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:36<00:00, 77.34s/it, loss=0.5517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.8121, Train Acc: 0.5429 | Val Loss: 0.7751, Val Acc: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:08<00:00, 80.96s/it, loss=0.9834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Learning rate reduced from 0.000100 to 0.000050\n",
      "Epoch 5: Train Loss: 0.7881, Train Acc: 0.5571 | Val Loss: 0.7174, Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:54<00:00, 79.44s/it, loss=0.7195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.7063, Train Acc: 0.5286 | Val Loss: 0.7198, Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:47<00:00, 78.56s/it, loss=0.7634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.7158, Train Acc: 0.6000 | Val Loss: 0.7433, Val Acc: 0.6667\n",
      "âœ“ Saved best model with Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:38<00:00, 77.57s/it, loss=0.7498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.7082, Train Acc: 0.5714 | Val Loss: 0.7507, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:13<00:00, 81.52s/it, loss=0.8497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.7864, Train Acc: 0.5143 | Val Loss: 0.7571, Val Acc: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:37<00:00, 77.50s/it, loss=0.4129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.6070, Train Acc: 0.6857 | Val Loss: 0.7382, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:32<00:00, 76.91s/it, loss=0.3459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Learning rate reduced from 0.000050 to 0.000025\n",
      "Epoch 11: Train Loss: 0.5743, Train Acc: 0.7429 | Val Loss: 0.7451, Val Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:12<00:00, 81.38s/it, loss=0.4911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.6765, Train Acc: 0.6429 | Val Loss: 0.7513, Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:53<00:00, 79.24s/it, loss=0.3655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.5978, Train Acc: 0.7286 | Val Loss: 0.7581, Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [12:45<00:00, 85.11s/it, loss=0.4386]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Improved Deepfake Detection: CNN vs TCN Comparison\n",
    "Fixed temporal modeling and robust training\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install(package):\n",
    "    \"\"\"Auto-install missing packages\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "        print(f\"âœ“ Installed {package}\")\n",
    "    except:\n",
    "        print(f\"! Warning: Could not install {package}, continuing...\")\n",
    "\n",
    "# Auto-install required packages\n",
    "required_packages = {\n",
    "    'torch': 'torch torchvision',\n",
    "    'cv2': 'opencv-python',\n",
    "    'numpy': 'numpy',\n",
    "    'sklearn': 'scikit-learn',\n",
    "    'PIL': 'Pillow',\n",
    "    'tqdm': 'tqdm',\n",
    "    'matplotlib': 'matplotlib'\n",
    "}\n",
    "\n",
    "print(\"=== Checking and installing dependencies ===\")\n",
    "for module, package in required_packages.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install(package)\n",
    "\n",
    "# Now import everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n=== Using device: {DEVICE} ===\")\n",
    "\n",
    "# Paths\n",
    "DATA_PATHS = {\n",
    "    'Original': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\original\",\n",
    "    'NeuralTextures': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\NeuralTextures\",\n",
    "    'FaceSwap': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\FaceSwap\",\n",
    "    'FaceShifter': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\FaceShifter\",\n",
    "    'Face2Face': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\Face2Face\",\n",
    "    'Deepfakes': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\Deepfakes\",\n",
    "    'DeepFakeDetection': r\"C:\\Users\\chakr\\Downloads\\archive (3)\\FaceForensics++_C23\\DeepFakeDetection\"\n",
    "}\n",
    "\n",
    "# Improved Hyperparameters\n",
    "IMG_SIZE = 128\n",
    "SEQUENCE_LENGTH = 16  # More frames for better temporal patterns\n",
    "BATCH_SIZE = 8  # Increased for stability\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.0001  # Lower initial learning rate\n",
    "MAX_VIDEOS_PER_CLASS = 50\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"Enhanced dataset with data augmentation\"\"\"\n",
    "    def __init__(self, data_paths, sequence_length=16, img_size=128, max_videos=50, augment=False):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.data = []\n",
    "        \n",
    "        print(\"\\n=== Loading dataset ===\")\n",
    "        \n",
    "        # Load real videos (label = 0)\n",
    "        real_path = Path(data_paths['Original'])\n",
    "        if real_path.exists():\n",
    "            real_videos = list(real_path.glob('**/*.mp4'))[:max_videos]\n",
    "            self.data.extend([(str(v), 0) for v in real_videos])\n",
    "            print(f\"Loaded {len(real_videos)} real videos\")\n",
    "        \n",
    "        # Load fake videos (label = 1)\n",
    "        fake_count = 0\n",
    "        for key in ['NeuralTextures', 'FaceSwap', 'Deepfakes', 'Face2Face', 'FaceShifter']:\n",
    "            if key in data_paths:\n",
    "                fake_path = Path(data_paths[key])\n",
    "                if fake_path.exists():\n",
    "                    fake_videos = list(fake_path.glob('**/*.mp4'))[:max_videos//5]\n",
    "                    self.data.extend([(str(v), 1) for v in fake_videos])\n",
    "                    fake_count += len(fake_videos)\n",
    "                    print(f\"Loaded {len(list(fake_path.glob('**/*.mp4'))[:max_videos//5])} {key} videos\")\n",
    "        \n",
    "        print(f\"Total fake videos: {fake_count}\")\n",
    "        print(f\"Total dataset size: {len(self.data)} videos\")\n",
    "        \n",
    "        # Shuffle data\n",
    "        random.shuffle(self.data)\n",
    "        \n",
    "        if len(self.data) == 0:\n",
    "            raise ValueError(\"No videos found! Check your paths.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            frames = self.extract_frames(video_path)\n",
    "            if self.augment:\n",
    "                frames = self.augment_frames(frames)\n",
    "            return frames, label\n",
    "        except Exception as e:\n",
    "            print(f\"! Error loading {video_path}: {e}\")\n",
    "            # Return a valid tensor instead of random\n",
    "            frames = torch.zeros(self.sequence_length, 3, self.img_size, self.img_size)\n",
    "            return frames, label\n",
    "    \n",
    "    def extract_frames(self, video_path):\n",
    "        \"\"\"Extract frames from video with better error handling\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        \n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        if total_frames == 0:\n",
    "            cap.release()\n",
    "            raise ValueError(f\"No frames in video: {video_path}\")\n",
    "        \n",
    "        # Sample frames evenly\n",
    "        if total_frames < self.sequence_length:\n",
    "            indices = list(range(total_frames))\n",
    "            while len(indices) < self.sequence_length:\n",
    "                indices.extend(list(range(total_frames)))\n",
    "            indices = indices[:self.sequence_length]\n",
    "        else:\n",
    "            indices = np.linspace(0, total_frames-1, self.sequence_length, dtype=int)\n",
    "        \n",
    "        for idx in indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                frame = cv2.resize(frame, (self.img_size, self.img_size))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = frame.astype(np.float32) / 255.0\n",
    "                # Normalize\n",
    "                frame = (frame - 0.5) / 0.5\n",
    "                frame = torch.from_numpy(frame).permute(2, 0, 1)\n",
    "                frames.append(frame)\n",
    "            else:\n",
    "                if frames:\n",
    "                    frames.append(frames[-1].clone())\n",
    "                else:\n",
    "                    frames.append(torch.zeros(3, self.img_size, self.img_size))\n",
    "        \n",
    "        cap.release()\n",
    "        return torch.stack(frames)\n",
    "    \n",
    "    def augment_frames(self, frames):\n",
    "        \"\"\"Apply data augmentation\"\"\"\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            frames = torch.flip(frames, dims=[3])\n",
    "        \n",
    "        # Random brightness adjustment\n",
    "        if random.random() > 0.5:\n",
    "            brightness_factor = random.uniform(0.8, 1.2)\n",
    "            frames = frames * brightness_factor\n",
    "            frames = torch.clamp(frames, -1, 1)\n",
    "        \n",
    "        return frames\n",
    "\n",
    "\n",
    "class ImprovedCNN(nn.Module):\n",
    "    \"\"\"Improved CNN with better architecture\"\"\"\n",
    "    def __init__(self):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Global pooling\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len, channels, height, width]\n",
    "        batch_size, seq_len = x.shape[:2]\n",
    "        \n",
    "        # Process all frames\n",
    "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
    "        x = self.features(x)\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        # Temporal pooling (max and average)\n",
    "        x_max = x.max(dim=1)[0]\n",
    "        x_avg = x.mean(dim=1)\n",
    "        x = x_max + x_avg  # Combine both\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"Fixed Temporal Convolutional Block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        \n",
    "        # Use causal padding to preserve sequence length\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=self.padding, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                              padding=self.padding, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Residual connection\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        out = self.conv1(x)\n",
    "        if self.padding > 0:\n",
    "            out = out[:, :, :-self.padding]  # Remove future padding\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        if self.padding > 0:\n",
    "            out = out[:, :, :-self.padding]\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        \n",
    "        # Match dimensions\n",
    "        if out.size(2) != res.size(2):\n",
    "            res = res[:, :, :out.size(2)]\n",
    "        \n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class ImprovedTCN(nn.Module):\n",
    "    \"\"\"Improved TCN model with fixed temporal convolutions\"\"\"\n",
    "    def __init__(self):\n",
    "        super(ImprovedTCN, self).__init__()\n",
    "        \n",
    "        # Spatial feature extractor\n",
    "        self.spatial = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        # Temporal feature extractor (TCN)\n",
    "        self.temporal = nn.Sequential(\n",
    "            TemporalBlock(256, 256, kernel_size=3, dilation=1),\n",
    "            TemporalBlock(256, 256, kernel_size=3, dilation=2),\n",
    "            TemporalBlock(256, 256, kernel_size=3, dilation=4),\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len, channels, height, width]\n",
    "        batch_size, seq_len = x.shape[:2]\n",
    "        \n",
    "        # Extract spatial features\n",
    "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
    "        x = self.spatial(x)\n",
    "        x = x.view(batch_size, 256, seq_len)\n",
    "        \n",
    "        # Extract temporal features\n",
    "        x = self.temporal(x)\n",
    "        \n",
    "        # Global temporal pooling (max + average)\n",
    "        x_max = torch.max(x, dim=2)[0]\n",
    "        x_avg = torch.mean(x, dim=2)\n",
    "        x = x_max + x_avg\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, model_name, epochs=25):\n",
    "    \"\"\"Training function with learning rate scheduling\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                      factor=0.5, patience=3)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_labels = [], []\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        for batch_idx, (frames, labels) in enumerate(pbar):\n",
    "            try:\n",
    "                frames, labels = frames.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(frames)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "                train_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            except Exception as e:\n",
    "                print(f\"! Error in batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = accuracy_score(train_labels, train_preds)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for frames, labels in val_loader:\n",
    "                try:\n",
    "                    frames, labels = frames.to(DEVICE), labels.to(DEVICE)\n",
    "                    outputs = model(frames)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    val_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "                    val_labels.extend(labels.cpu().numpy())\n",
    "                except Exception as e:\n",
    "                    print(f\"! Validation error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_acc)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr != old_lr:\n",
    "            print(f\"âœ“ Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "            print(f\"âœ“ Saved best model with Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f'{model_name}_best.pth'))\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for frames, labels in tqdm(test_loader, desc=f\"Evaluating {model_name}\"):\n",
    "            try:\n",
    "                frames = frames.to(DEVICE)\n",
    "                outputs = model(frames)\n",
    "                all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "\n",
    "\n",
    "def plot_results(cnn_history, tcn_history, cnn_results, tcn_results):\n",
    "    \"\"\"Plot comparison results\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Training Loss\n",
    "    axes[0, 0].plot(cnn_history['train_loss'], label='CNN Train', marker='o', linewidth=2)\n",
    "    axes[0, 0].plot(tcn_history['train_loss'], label='TCN Train', marker='s', linewidth=2)\n",
    "    axes[0, 0].set_title('Training Loss Comparison', fontsize=14, weight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation Accuracy\n",
    "    axes[0, 1].plot(cnn_history['val_acc'], label='CNN Val', marker='o', linewidth=2)\n",
    "    axes[0, 1].plot(tcn_history['val_acc'], label='TCN Val', marker='s', linewidth=2)\n",
    "    axes[0, 1].set_title('Validation Accuracy Comparison', fontsize=14, weight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final Metrics Comparison\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    cnn_vals = [cnn_results[m] for m in metrics]\n",
    "    tcn_vals = [tcn_results[m] for m in metrics]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[1, 0].bar(x - width/2, cnn_vals, width, label='CNN', alpha=0.8, color='#2196F3')\n",
    "    bars2 = axes[1, 0].bar(x + width/2, tcn_vals, width, label='TCN', alpha=0.8, color='#4CAF50')\n",
    "    axes[1, 0].set_title('Final Performance Metrics', fontsize=14, weight='bold')\n",
    "    axes[1, 0].set_ylabel('Score')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels([m.capitalize() for m in metrics])\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, axis='y', alpha=0.3)\n",
    "    axes[1, 0].set_ylim([0, 1])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                          f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Improvement Table\n",
    "    axes[1, 1].axis('off')\n",
    "    improvements = [(m, tcn_vals[i] - cnn_vals[i], \n",
    "                    (tcn_vals[i] - cnn_vals[i])/cnn_vals[i]*100 if cnn_vals[i] > 0 else 0) \n",
    "                   for i, m in enumerate(metrics)]\n",
    "    \n",
    "    table_data = [['Metric', 'CNN', 'TCN', 'Improvement']]\n",
    "    for i, m in enumerate(metrics):\n",
    "        improvement_str = f'+{improvements[i][2]:.2f}%' if improvements[i][1] >= 0 else f'{improvements[i][2]:.2f}%'\n",
    "        table_data.append([\n",
    "            m.capitalize(),\n",
    "            f'{cnn_vals[i]:.4f}',\n",
    "            f'{tcn_vals[i]:.4f}',\n",
    "            improvement_str\n",
    "        ])\n",
    "    \n",
    "    table = axes[1, 1].table(cellText=table_data, loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    for i in range(len(table_data)):\n",
    "        if i == 0:\n",
    "            for j in range(4):\n",
    "                table[(i, j)].set_facecolor('#4CAF50')\n",
    "                table[(i, j)].set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            if tcn_vals[i-1] > cnn_vals[i-1]:\n",
    "                table[(i, 3)].set_facecolor('#E8F5E9')\n",
    "            else:\n",
    "                table[(i, 3)].set_facecolor('#FFEBEE')\n",
    "    \n",
    "    axes[1, 1].set_title('TCN vs CNN Performance Summary', pad=20, fontsize=12, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('deepfake_comparison_improved.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nâœ“ Results saved to 'deepfake_comparison_improved.png'\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        # Load dataset with augmentation for training\n",
    "        print(\"\\n=== Creating training dataset (with augmentation) ===\")\n",
    "        train_dataset_full = VideoDataset(DATA_PATHS, SEQUENCE_LENGTH, IMG_SIZE, \n",
    "                                         MAX_VIDEOS_PER_CLASS, augment=True)\n",
    "        \n",
    "        print(\"\\n=== Creating validation/test dataset (no augmentation) ===\")\n",
    "        eval_dataset_full = VideoDataset(DATA_PATHS, SEQUENCE_LENGTH, IMG_SIZE, \n",
    "                                        MAX_VIDEOS_PER_CLASS, augment=False)\n",
    "        \n",
    "        # Split dataset\n",
    "        total_size = len(train_dataset_full)\n",
    "        train_size = int(0.7 * total_size)\n",
    "        val_size = int(0.15 * total_size)\n",
    "        test_size = total_size - train_size - val_size\n",
    "        \n",
    "        # Use augmented data for training\n",
    "        train_indices = list(range(train_size))\n",
    "        # Use non-augmented data for validation and testing\n",
    "        val_indices = list(range(train_size, train_size + val_size))\n",
    "        test_indices = list(range(train_size + val_size, total_size))\n",
    "        \n",
    "        train_dataset = torch.utils.data.Subset(train_dataset_full, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(eval_dataset_full, val_indices)\n",
    "        test_dataset = torch.utils.data.Subset(eval_dataset_full, test_indices)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                                 num_workers=0, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                               num_workers=0, pin_memory=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                                num_workers=0, pin_memory=True)\n",
    "        \n",
    "        print(f\"\\nDataset split: Train={train_size}, Val={val_size}, Test={test_size}\")\n",
    "        \n",
    "        # Train CNN\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRAINING IMPROVED CNN MODEL\")\n",
    "        print(\"=\"*70)\n",
    "        cnn_model = ImprovedCNN().to(DEVICE)\n",
    "        cnn_history = train_model(cnn_model, train_loader, val_loader, \"CNN\", EPOCHS)\n",
    "        cnn_results = evaluate_model(cnn_model, test_loader, \"CNN\")\n",
    "        \n",
    "        # Train TCN\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRAINING IMPROVED TCN MODEL\")\n",
    "        print(\"=\"*70)\n",
    "        tcn_model = ImprovedTCN().to(DEVICE)\n",
    "        tcn_history = train_model(tcn_model, train_loader, val_loader, \"TCN\", EPOCHS)\n",
    "        tcn_results = evaluate_model(tcn_model, test_loader, \"TCN\")\n",
    "        \n",
    "        # Plot results\n",
    "        plot_results(cnn_history, tcn_history, cnn_results, tcn_results)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nðŸ“Š FINAL RESULTS:\")\n",
    "        print(f\"  CNN - Accuracy: {cnn_results['accuracy']:.4f} | F1-Score: {cnn_results['f1']:.4f}\")\n",
    "        print(f\"  TCN - Accuracy: {tcn_results['accuracy']:.4f} | F1-Score: {tcn_results['f1']:.4f}\")\n",
    "        print(f\"\\nðŸŽ¯ TCN Improvement over CNN:\")\n",
    "        print(f\"  Accuracy: {(tcn_results['accuracy'] - cnn_results['accuracy']):.4f} \"\n",
    "              f\"({((tcn_results['accuracy'] - cnn_results['accuracy'])/cnn_results['accuracy']*100):.2f}%)\")\n",
    "        print(f\"  F1-Score: {(tcn_results['f1'] - cnn_results['f1']):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n! CRITICAL ERROR: {e}\")\n",
    "        print(\"! Check your data paths and ensure videos exist.\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7828a761-7adf-4ffc-b800-43feedde460e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
